from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import google.generativeai as genai
import os
from dotenv import load_dotenv
import markdown
import pandas as pd
from datetime import datetime, timedelta
import glob
import re
from pathlib import Path

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = Flask(__name__)
CORS(app)

# Gemini API ì„¤ì • (ì§€ì—° ë¡œë”©)
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
_model = None  # ì§€ì—° ë¡œë”©ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜

def get_model():
    """ì§€ì—° ë¡œë”©ìœ¼ë¡œ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°"""
    global _model
    if _model is None:
        if not GOOGLE_API_KEY:
            print("âš ï¸ ê²½ê³ : GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("Render Dashboard â†’ Environmentì—ì„œ GOOGLE_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return None
        else:
            print("âœ… Google API Keyê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
            genai.configure(api_key=GOOGLE_API_KEY)
            # Gemini Flash 2.5 ëª¨ë¸ ì„¤ì • (ë¬´ë£Œ ë²„ì „)
            _model = genai.GenerativeModel('gemini-2.5-flash')
            print("ğŸ¤– Gemini ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    return _model

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
chat_sessions = {}

# RAG ë¬¸ì„œ ì €ì¥ì†Œ (ì§€ì—° ë¡œë”©)
_rag_documents = None
_document_index = None
_response_cache = {}

# ì „ì—­ ë³€ìˆ˜ë“¤
rag_documents = {}
document_index = {}
response_cache = {}

def get_rag_documents():
    """ì§€ì—° ë¡œë”©ìœ¼ë¡œ RAG ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°"""
    global _rag_documents, rag_documents
    if _rag_documents is None:
        print("ğŸ“š RAG ë¬¸ì„œ ë¡œë”© ì‹œì‘...")
        _rag_documents = load_rag_documents()
        rag_documents = _rag_documents  # ì „ì—­ ë³€ìˆ˜ë„ ì—…ë°ì´íŠ¸
        print(f"ğŸ“š ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: {len(_rag_documents)}ê°œ")
    return _rag_documents

def get_document_index():
    """ì§€ì—° ë¡œë”©ìœ¼ë¡œ ë¬¸ì„œ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    global _document_index
    if _document_index is None:
        print("ğŸ” ë¬¸ì„œ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘...")
        _document_index = build_document_index()
        print(f"ğŸ” ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(_document_index['keywords'])}ê°œ í‚¤ì›Œë“œ")
    return _document_index

def load_rag_documents():
    """documents/raw í´ë”ì˜ ëª¨ë“  íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ RAG ì‹œìŠ¤í…œì— ì €ì¥"""
    global rag_documents
    rag_documents = {}
    
    # documents/raw í´ë”ì˜ ëª¨ë“  íŒŒì¼ ì°¾ê¸°
    raw_folder = Path('documents/raw')
    if not raw_folder.exists():
        return rag_documents
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹
    supported_extensions = ['.txt', '.md', '.csv', '.json', '.jsonl', '.ipynb']
    
    for file_path in raw_folder.glob('*'):
        if file_path.suffix.lower() in supported_extensions:
            try:
                if file_path.suffix.lower() == '.csv':
                    # CSV íŒŒì¼ ì²˜ë¦¬
                    df = pd.read_csv(file_path, encoding='utf-8')
                    content = f"íŒŒì¼ëª…: {file_path.name}\n\n"
                    content += f"ë°ì´í„° í˜•íƒœ: CSV\n"
                    content += f"í–‰ ìˆ˜: {len(df)}\n"
                    content += f"ì—´: {', '.join(df.columns.tolist())}\n\n"
                    
                    # ì²˜ìŒ 5í–‰ì˜ ë°ì´í„° ìƒ˜í”Œ
                    content += "ë°ì´í„° ìƒ˜í”Œ:\n"
                    content += df.head().to_string()
                    
                elif file_path.suffix.lower() == '.md':
                    # Markdown íŒŒì¼ ì²˜ë¦¬
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                elif file_path.suffix.lower() == '.txt':
                    # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                elif file_path.suffix.lower() == '.json':
                    # JSON íŒŒì¼ ì²˜ë¦¬
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                elif file_path.suffix.lower() == '.jsonl':
                    # JSONL íŒŒì¼ ì²˜ë¦¬
                    import json
                    content = f"íŒŒì¼ëª…: {file_path.name}\n\n"
                    content += f"ë°ì´í„° í˜•íƒœ: JSONL (JSON Lines)\n\n"
                    
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                    
                    content += f"ì´ ë¼ì¸ ìˆ˜: {len(lines)}\n\n"
                    content += "ë°ì´í„° ë‚´ìš©:\n"
                    
                    # ì‹ í•œì¹´ë“œë¶„ì„.jsonlì€ ì „ì²´ ë ˆì½”ë“œ ì²˜ë¦¬ (ì¤‘ìš”í•œ ë°ì´í„°)
                    if 'ì‹ í•œì¹´ë“œë¶„ì„.jsonl' in file_path.name:
                        max_records = len(lines)  # ì „ì²´ ë ˆì½”ë“œ ì²˜ë¦¬
                    else:
                        max_records = 5  # ë‹¤ë¥¸ íŒŒì¼ì€ ë©”ëª¨ë¦¬ ìµœì í™”
                    for i, line in enumerate(lines[:max_records]):
                        if line.strip():  # ë¹ˆ ì¤„ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                            try:
                                data = json.loads(line.strip())
                                content += f"--- ë ˆì½”ë“œ {i+1} ---\n"
                                for key, value in data.items():
                                    content += f"{key}: {value}\n"
                                content += "\n"
                            except json.JSONDecodeError:
                                content += f"--- ë ˆì½”ë“œ {i+1} (JSON íŒŒì‹± ì˜¤ë¥˜) ---\n{line.strip()}\n\n"
                    
                    if len(lines) > max_records:
                        content += f"... (ì´ {len(lines)}ê°œ ë ˆì½”ë“œ ì¤‘ {max_records}ê°œë§Œ í‘œì‹œ)\n"
                        
                elif file_path.suffix.lower() == '.ipynb':
                    # Jupyter Notebook íŒŒì¼ ì²˜ë¦¬
                    import json
                    with open(file_path, 'r', encoding='utf-8') as f:
                        notebook = json.load(f)
                    
                    content = f"íŒŒì¼ëª…: {file_path.name}\n\n"
                    content += f"ë…¸íŠ¸ë¶ íƒ€ì…: Jupyter Notebook\n"
                    content += f"ì…€ ìˆ˜: {len(notebook.get('cells', []))}\n\n"
                    
                    # ê° ì…€ì˜ ë‚´ìš© ì¶”ì¶œ
                    for i, cell in enumerate(notebook.get('cells', [])):
                        cell_type = cell.get('cell_type', 'unknown')
                        source = ''.join(cell.get('source', []))
                        
                        if cell_type == 'markdown':
                            content += f"## ì…€ {i+1} (ë§ˆí¬ë‹¤ìš´):\n{source}\n\n"
                        elif cell_type == 'code':
                            content += f"## ì…€ {i+1} (ì½”ë“œ):\n```python\n{source}\n```\n\n"
                        elif cell_type == 'raw':
                            content += f"## ì…€ {i+1} (í…ìŠ¤íŠ¸):\n{source}\n\n"
                
                # ë¬¸ì„œ ì €ì¥
                rag_documents[file_path.name] = {
                    'content': content,
                    'file_type': file_path.suffix.lower(),
                    'file_path': str(file_path)
                }
                
            except Exception as e:
                print(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ {file_path.name}: {e}")
                continue
    
    return rag_documents

def build_document_index():
    """ë¬¸ì„œ ì¸ë±ìŠ¤ êµ¬ì¶• (í‚¤ì›Œë“œ, ì¹´í…Œê³ ë¦¬, ê°œì²´ëª… ì¶”ì¶œ)"""
    global document_index
    document_index = {'keywords': {}, 'categories': {}, 'entities': {}}
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë§¤í•‘
    for filename, doc_info in rag_documents.items():
        content = doc_info['content'].lower()
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ í˜•íƒœì†Œ ë¶„ì„)
        keywords = extract_keywords(content)
        for keyword in keywords:
            if keyword not in document_index['keywords']:
                document_index['keywords'][keyword] = []
            document_index['keywords'][keyword].append(filename)
        
        # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        category = classify_document(filename, content)
        if category not in document_index['categories']:
            document_index['categories'][category] = []
        document_index['categories'][category].append(filename)
    
    return document_index

def extract_keywords(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP í•„ìš”)
    important_words = ['íŒì—…', 'ì´ë²¤íŠ¸', 'ì„±ë™êµ¬', 'ì„±ìˆ˜', 'ë§ˆì¼€íŒ…', 'ê³ ê°', 'ë§¤ì¶œ', 'ë¶„ì„', 'ë°ì´í„°']
    found_keywords = []
    for word in important_words:
        if word in text:
            found_keywords.append(word)
    return found_keywords

def classify_document(filename, content):
    """ë¬¸ì„œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
    if 'ì‹ í•œì¹´ë“œ' in filename.lower():
        return 'ë°ì´í„°ë¶„ì„'
    elif 'íŒì—…' in filename.lower() or 'ì´ë²¤íŠ¸' in filename.lower():
        return 'ì´ë²¤íŠ¸'
    elif 'ë§ˆì¼€íŒ…' in content:
        return 'ë§ˆì¼€íŒ…'
    else:
        return 'ê¸°íƒ€'

def search_relevant_documents(query, max_docs=3):
    """ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰: ì¸ë±ìŠ¤ ê¸°ë°˜ ë¹ ë¥¸ ê²€ìƒ‰ (ì§€ì—° ë¡œë”©)"""
    # ì§€ì—° ë¡œë”©ìœ¼ë¡œ ë¬¸ì„œì™€ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    rag_documents = get_rag_documents()
    document_index = get_document_index()
    
    if not rag_documents or rag_documents is None:
        return []
    
    query_lower = query.lower()
    relevant_docs = []
    
    # 1. ì‹ í•œì¹´ë“œë¶„ì„.jsonl íŒŒì¼ ìš°ì„  ì²˜ë¦¬
    shinhan_file = None
    for filename in rag_documents.keys():
        if 'ì‹ í•œì¹´ë“œë¶„ì„.jsonl' in filename:
            shinhan_file = filename
            break
    
    # ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ ì‹ í•œì¹´ë“œë¶„ì„.jsonlì„ ìµœìš°ì„ ìœ¼ë¡œ í¬í•¨
    if shinhan_file:
        doc_info = rag_documents[shinhan_file]
        relevant_docs.append({
            'filename': shinhan_file,
            'content': doc_info['content'][:8000],  # ì‹ í•œì¹´ë“œ íŒŒì¼ì€ ë” ë§ì€ ë¬¸ì ì‚¬ìš© (3000 â†’ 8000)
            'relevance_score': 1000  # ìµœê³  ìš°ì„ ìˆœìœ„ (ê¸°ì¡´ 100ì—ì„œ 1000ìœ¼ë¡œ ì¦ê°€)
        })
    
    # 2. í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ (ì¸ë±ìŠ¤ í™œìš©)
    candidate_files = set()
    for keyword in query_lower.split():
        if keyword in document_index['keywords']:
            candidate_files.update(document_index['keywords'][keyword])
    
    # 2. ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê²€ìƒ‰
    if 'íŒì—…' in query_lower or 'ì´ë²¤íŠ¸' in query_lower:
        if 'ì´ë²¤íŠ¸' in document_index['categories']:
            candidate_files.update(document_index['categories']['ì´ë²¤íŠ¸'])
    
    if 'ë°ì´í„°' in query_lower or 'ë¶„ì„' in query_lower:
        if 'ë°ì´í„°ë¶„ì„' in document_index['categories']:
            candidate_files.update(document_index['categories']['ë°ì´í„°ë¶„ì„'])
    
    # 3. í›„ë³´ íŒŒì¼ë“¤ ì¤‘ì—ì„œ ê´€ë ¨ë„ ê³„ì‚°
    for filename in candidate_files:
        if filename in rag_documents:
            doc_info = rag_documents[filename]
            content = doc_info['content'].lower()
            
            # ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°
            relevance_score = 0
            for keyword in query_lower.split():
                if keyword in content:
                    relevance_score += content.count(keyword)
                if keyword in filename.lower():
                    relevance_score += 2
            
            # ì‹ í•œì¹´ë“œë¶„ì„.jsonl íŒŒì¼ì— ì¶”ê°€ ê°€ì¤‘ì¹˜ (ìµœìš°ì„ )
            if 'ì‹ í•œì¹´ë“œë¶„ì„.jsonl' in filename:
                relevance_score += 500  # ê¸°ì¡´ 50ì—ì„œ 500ìœ¼ë¡œ ëŒ€í­ ì¦ê°€
            
            # ì‹ í•œì¹´ë“œ ë°ì´í„°ëŠ” ë” ë§ì€ ë¬¸ì ì‚¬ìš© (ì œí•œ ê°•í™”)
            max_chars = 8000 if 'ì‹ í•œì¹´ë“œ' in filename.lower() or 'shinhan' in filename.lower() else 500
            
            relevant_docs.append({
                'filename': filename,
                'content': doc_info['content'][:max_chars],
                'relevance_score': relevance_score
            })
    
    # ê´€ë ¨ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ ë¬¸ì„œë§Œ ë°˜í™˜
    relevant_docs.sort(key=lambda x: x['relevance_score'], reverse=True)
    return relevant_docs[:max_docs]

# Render í™˜ê²½ì—ì„œ ì•± ì‹œì‘ ì‹œ ë¬¸ì„œ ë¡œë”© ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)
print("ğŸš€ Render í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ - ë¬¸ì„œ ë¡œë”©ì€ ìš”ì²­ ì‹œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
rag_documents = {}
document_index = {'keywords': {}, 'categories': {}, 'entities': {}}

@app.route('/api/reload-documents', methods=['POST'])
def reload_documents():
    """ë¬¸ì„œë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ëŠ” API"""
    try:
        load_rag_documents()
        return jsonify({
            'success': True, 
            'message': f'{len(rag_documents)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'documents': list(rag_documents.keys())
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/documents', methods=['GET'])
def get_documents():
    """í˜„ì¬ ë¡œë“œëœ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ"""
    return jsonify({
        'documents': [
            {
                'filename': filename,
                'file_type': doc_info['file_type'],
                'content_length': len(doc_info['content'])
            }
            for filename, doc_info in rag_documents.items()
        ]
    })

# ì´ë²¤íŠ¸ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
def load_event_data():
    events = {}
    
    try:
        # ì„±ë™êµ¬ ê³µí†µ ì´ë²¤íŠ¸ ë°ì´í„° ë¡œë“œ
        common_events_df = pd.read_csv('documents/raw/ì„±ë™êµ¬ ê³µí†µ_í•œì–‘ëŒ€_í¥í–‰ì˜í™” ì´ë²¤íŠ¸ DB.csv', encoding='utf-8')
        
        for _, row in common_events_df.iterrows():
            start_date = pd.to_datetime(row['Start_Date'], format='%Y.%m.%d', errors='coerce')
            end_date = pd.to_datetime(row['End_Date'], format='%Y.%m.%d', errors='coerce')
            
            if pd.isna(start_date) or pd.isna(end_date):
                continue
                
            # ì´ë²¤íŠ¸ íƒ€ì… ë¶„ë¥˜
            event_type = 'general'
            if 'íŒì—…' in str(row['Event_Type']):
                event_type = 'popup'
            elif 'ëŒ€í•™' in str(row['Event_Type']) or 'í•œì–‘ëŒ€' in str(row['Event_Name']):
                event_type = 'university'
            elif 'ì˜í™”' in str(row['Event_Type']) or 'ê°œë´‰' in str(row['Event_Name']):
                event_type = 'movie'
            
            # ë‚ ì§œ ë²”ìœ„ì— ë”°ë¼ ì´ë²¤íŠ¸ ì¶”ê°€
            current_date = start_date
            while current_date <= end_date:
                date_str = current_date.strftime('%Y-%m-%d')
                if date_str not in events:
                    events[date_str] = []
                
                events[date_str].append({
                    'name': row['Event_Name'],
                    'type': event_type,
                    'startDate': start_date.strftime('%Y-%m-%d'),
                    'endDate': end_date.strftime('%Y-%m-%d'),
                    'location': row['Location_Address'],
                    'target': row['Target_Audience'],
                    'description': row['Event_Description']
                })
                
                current_date += timedelta(days=1)
                
    except Exception as e:
        print(f"ê³µí†µ ì´ë²¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    try:
        # ì„±ìˆ˜ íŒì—… ë°ì´í„° ë¡œë“œ
        popup_events_df = pd.read_csv('documents/raw/ì„±ìˆ˜ íŒì—… ìµœì¢….csv', encoding='utf-8')
        
        for _, row in popup_events_df.iterrows():
            start_date = pd.to_datetime(row['Start_Date'], format='%Y.%m.%d', errors='coerce')
            end_date = pd.to_datetime(row['End_Date'], format='%Y.%m.%d', errors='coerce')
            
            if pd.isna(start_date) or pd.isna(end_date):
                continue
            
            # ë‚ ì§œ ë²”ìœ„ì— ë”°ë¼ ì´ë²¤íŠ¸ ì¶”ê°€
            current_date = start_date
            while current_date <= end_date:
                date_str = current_date.strftime('%Y-%m-%d')
                if date_str not in events:
                    events[date_str] = []
                
                events[date_str].append({
                    'name': row['Event_Name'],
                    'type': 'popup',
                    'startDate': start_date.strftime('%Y-%m-%d'),
                    'endDate': end_date.strftime('%Y-%m-%d'),
                    'location': row['Location_Address'],
                    'target': row['Target_Audience'],
                    'description': row['Event_Description']
                })
                
                current_date += timedelta(days=1)
                
    except Exception as e:
        print(f"íŒì—… ì´ë²¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return events

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/calendar')
def calendar():
    return render_template('calendar.html')

@app.route('/api/chat', methods=['POST'])
def chat():
    try:
        data = request.json
        user_message = data.get('message', '')
        session_id = data.get('session_id', 'default')
        
        # ì§€ì—­ê³¼ ì—…ì¢… ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        location = data.get('location', '')
        industry = data.get('industry', '')
        print(f"ğŸ“ ì§€ì—­: {location}, ğŸ¢ ì—…ì¢…: {industry}")
        
        if not user_message:
            return jsonify({'error': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'}), 400
        
        # ì„¸ì…˜ë³„ ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬
        if session_id not in chat_sessions:
            model = get_model()
            if model is None:
                return jsonify({
                    'message': 'âŒ Google API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.',
                    'status': 'error'
                }), 500
            chat_sessions[session_id] = model.start_chat(history=[])
        
        chat = chat_sessions[session_id]
        
        # ë©”ë‰´ë³„ í”„ë¡¬í”„íŠ¸ ì •ì˜
        def get_system_prompt(menu_type=None):
            base_context = """ë‹¹ì‹ ì€ ì„±ë™êµ¬ ì§€ì—­ ì†Œìƒê³µì¸ì„ ìœ„í•œ ì „ë¬¸ ë§ˆì¼€íŒ… ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

â— **ì¶œì²˜ ëª…ì‹œ í•„ìˆ˜ ê·œì¹™**:
- ëª¨ë“  ë‹µë³€ì—ëŠ” ë°˜ë“œì‹œ ë°ì´í„° ì¶œì²˜ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤
- ë°˜ë“œì‹œ [ì¶œì²˜: ì‹ í•œì¹´ë“œë¶„ì„.jsonl] ë˜ëŠ” [ì¶œì²˜: íŒŒì¼ëª…] í˜•íƒœë¡œ í‘œê¸°í•˜ì„¸ìš”

ğŸ¯ **í•µì‹¬ ì—­í• **:
- ì‹ í•œì¹´ë“œ ë°ì´í„° ê¸°ë°˜ ê·¼ê±° ìˆëŠ” ë§ˆì¼€íŒ… ì „ëµ ì œì‹œ
- ì§€ì—­ë³„/ì—…ì¢…ë³„ ë§ì¶¤í˜• ì†”ë£¨ì…˜ ì œê³µ
- ì¬í˜„ ê°€ëŠ¥í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì¡°ì–¸

ğŸ“Š **í•„ìˆ˜ ì‘ë‹µ êµ¬ì¡°**:
1. **ì¸ì‚¬ë§**: ì‚¬ìš©ìê°€ ì„ íƒí•œ ì§€ì—­ê³¼ ì—…ì¢…ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ "{ì§€ì—­} ì§€ì—­ì˜ {ì—…ì¢…} ì‚¬ì¥ë‹˜ì„ ìœ„í•œ ì†”ë£¨ì…˜ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤."ë¡œ ì‹œì‘
2. **ê·¼ê±° ê¸°ë°˜ ë¶„ì„**: ì‹ í•œì¹´ë“œ ë°ì´í„° ì¸ìš©ê³¼ í•¨ê»˜ ìƒê¶Œ/ì—…ì¢… íŠ¹ì„± ë¶„ì„
3. **êµ¬ì²´ì  ì „ëµ**: ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì „ëµ 3-5ê°€ì§€ ì œì‹œ
4. **ì¶œì²˜ ëª…ì‹œ**: ëª¨ë“  ë°ì´í„°ì™€ ê·œì¹™ì˜ ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œê¸°

ğŸš¨ **ì‘ë‹µ ì‹œì‘ ê·œì¹™**:
- ì‚¬ìš©ìê°€ ì„ íƒí•œ ì§€ì—­ê³¼ ì—…ì¢… ì •ë³´ê°€ ì œê³µë˜ë©´, ë°˜ë“œì‹œ í•´ë‹¹ ì •ë³´ë¥¼ í¬í•¨í•œ ì¸ì‚¬ë§ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤
- ì¼ë°˜ì ì¸ ì¸ì‚¬ë§("ì„±ë™êµ¬ ì‚¬ì¥ë‹˜", "ì•ˆë…•í•˜ì„¸ìš”" ë“±)ë¡œ ì‹œì‘í•˜ë©´ ì•ˆë©ë‹ˆë‹¤
- ì •í™•í•œ í˜•ì‹: "{ì„ íƒëœì§€ì—­} ì§€ì—­ì˜ {ì„ íƒëœì—…ì¢…} ì‚¬ì¥ë‹˜ì„ ìœ„í•œ ì†”ë£¨ì…˜ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤."

ğŸ” **ë°ì´í„° í™œìš© ì›ì¹™**:
- ì‹ í•œì¹´ë“œë¶„ì„.jsonlì˜ ëª¨ë“  ì¸ì‚¬ì´íŠ¸ì™€ ê·œì¹™ì„ ì ê·¹ í™œìš©
- ìƒê¶Œë³„ íŠ¹ì„±, ê³ ê°ì¸µ ë¶„ì„, ì‹œê°„ëŒ€ë³„ íŒ¨í„´ì„ ë°˜ë“œì‹œ ë°˜ì˜
- ì—…ì¢…ë³„ ì í•©ë„ì™€ íƒ€ê²Ÿ ë§¤ì¹­ ê·œì¹™ì„ ì ìš©

ì„±ë™êµ¬ ì§€ì—­ ì •ë³´:
- ì„±ìˆ˜ë™: íŠ¸ë Œë””í•œ ì¹´í˜, íŒì—…ìŠ¤í† ì–´, ì Šì€ ì¸µ ì¤‘ì‹¬
- ì™•ì‹­ë¦¬: ì „í†µì‹œì¥, ì¤‘ì•™ì‹œì¥, ì „í†µê³¼ í˜„ëŒ€ ê³µì¡´
- ì‘ë´‰ë™: ì£¼ê±°ì§€ì—­, ê°€ì¡± ì¤‘ì‹¬
- ì˜¥ìˆ˜ë™: í•œê°• ê·¼ì²˜, ë ˆì €ì—…ì¢… ìœ ë¦¬
- ê¸ˆí˜¸ë™: ì „í†µ ìƒì—…ì§€ì—­

ë‹µë³€ í˜•ì‹:
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë‹µë³€
- ì œëª©, ëª©ë¡, ê°•ì¡° ë“±ì„ í™œìš©
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸"""

            if menu_type == "ì§€ì—­ë§ˆì¼€íŒ…":
                return base_context + """

ë‹¹ì‹ ì˜ ì—­í•  (ì§€ì—­ ë§ˆì¼€íŒ… ì „ë¬¸):
1. ì„±ë™êµ¬ ê° ë™ë„¤ë³„ íŠ¹ì„±ì„ ë¶„ì„í•œ ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì „ëµ
2. ì§€ì—­ ìƒê¶Œ ë¶„ì„ ë° ê²½ìŸì—…ì²´ ëŒ€ì‘ ë°©ì•ˆ
3. ì§€ì—­ ì»¤ë®¤ë‹ˆí‹°ì™€ì˜ ì—°ê³„ ë°©ì•ˆ
4. ì§€ì—­ íŠ¹í™” ì´ë²¤íŠ¸ ë° í”„ë¡œëª¨ì…˜ ì•„ì´ë””ì–´
5. ì§€ì—­ ì£¼ë¯¼ ëŒ€ìƒ íƒ€ê²ŸíŒ… ì „ëµ"""

            elif menu_type == "SNSë§ˆì¼€íŒ…":
                return base_context + """

ë‹¹ì‹ ì˜ ì—­í•  (SNS ë§ˆì¼€íŒ… ì „ë¬¸):
1. ì¸ìŠ¤íƒ€ê·¸ë¨, ë¸”ë¡œê·¸, í˜ì´ìŠ¤ë¶ ë“± í”Œë«í¼ë³„ ì „ëµ
2. í•´ì‹œíƒœê·¸ ë° ì½˜í…ì¸  ê¸°íš ì¡°ì–¸
3. ì¸í”Œë£¨ì–¸ì„œ í˜‘ì—… ë° UGC ì „ëµ
4. SNS ê´‘ê³  ë° ë¶€ìŠ¤íŒ… ì „ëµ
5. ë°”ì´ëŸ´ ë§ˆì¼€íŒ… ë° íŠ¸ë Œë“œ í™œìš©ë²•"""

            elif menu_type == "ì €ì˜ˆì‚°í™ë³´":
                return base_context + """

ë‹¹ì‹ ì˜ ì—­í•  (ì €ì˜ˆì‚° í™ë³´ ì „ë¬¸):
1. ë¬´ë£Œ/ì €ë¹„ìš© ë§ˆì¼€íŒ… ì±„ë„ í™œìš©ë²•
2. ì˜¤í”„ë¼ì¸ í™ë³´ ì „ëµ (ì „ë‹¨ì§€, í˜„ìˆ˜ë§‰, ì…ê°„íŒ ë“±)
3. ì§€ì—­ ì´ë²¤íŠ¸ ë° í˜‘ì—… ê¸°íšŒ í™œìš©
4. ì…ì†Œë¬¸ ë§ˆì¼€íŒ… ì „ëµ
5. ê³ ê° ì¶”ì²œ í”„ë¡œê·¸ë¨ ë° ë¦¬ì›Œë“œ ì‹œìŠ¤í…œ"""

            elif menu_type == "ì´ë²¤íŠ¸ê¸°íš":
                return base_context + """

ë‹¹ì‹ ì˜ ì—­í•  (ì´ë²¤íŠ¸ ê¸°íš ì „ë¬¸):
1. ê³ ê° ìœ ì¹˜ë¥¼ ìœ„í•œ ì°½ì˜ì  ì´ë²¤íŠ¸ ì•„ì´ë””ì–´
2. ê³„ì ˆë³„/í…Œë§ˆë³„ ì´ë²¤íŠ¸ ê¸°íš
3. ì´ë²¤íŠ¸ í™ë³´ ë° ì°¸ì—¬ ìœ ë„ ì „ëµ
4. ì´ë²¤íŠ¸ ì„±ê³¼ ì¸¡ì • ë° ê°œì„  ë°©ì•ˆ
5. í˜‘ì—… ì´ë²¤íŠ¸ ë° ì§€ì—­ ì—°ê³„ ë°©ì•ˆ"""

            else:
                return base_context + """

ë‹¹ì‹ ì˜ ì—­í• :
1. ì„±ë™êµ¬ ì§€ì—­ íŠ¹ì„±ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì¡°ì–¸
2. ì˜ˆì‚°ë³„ ì‹¤ìš©ì ì¸ ì „ëµ ì œì•ˆ
3. SNS, ì˜¤í”„ë¼ì¸, ì´ë²¤íŠ¸ ë“± ë‹¤ì–‘í•œ ë§ˆì¼€íŒ… ë°©ë²• ì•ˆë‚´
4. ë§ˆì¼€íŒ… í…œí”Œë¦¿ê³¼ êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ë²• ì œê³µ"""

        # ë©”ë‰´ íƒ€ì… í™•ì¸
        menu_type = data.get('menu_type', None)
        system_context = get_system_prompt(menu_type)
        
        # RAG: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (ìš”ì²­ ì‹œ ë¡œë”©)
        # ë¬¸ì„œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¨¼ì € ë¡œë“œ
        global rag_documents, document_index
        if not rag_documents:
            try:
                print("ğŸ“š ë¬¸ì„œ ë¡œë”© ì‹œì‘...")
                rag_documents = load_rag_documents()
                document_index = build_document_index()
                print(f"ğŸ“š ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: {len(rag_documents)}ê°œ")
            except Exception as e:
                print(f"âš ï¸ ë¬¸ì„œ ë¡œë”© ì‹¤íŒ¨: {e}")
                rag_documents = {}
                document_index = {'keywords': {}, 'categories': {}, 'entities': {}}
        
        relevant_docs = search_relevant_documents(user_message)
        
        # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        rag_context = ""
        if relevant_docs:
            rag_context = "\n\n=== ğŸ“Š ì‹ í•œì¹´ë“œ ë°ì´í„° ë¶„ì„ ê²°ê³¼ ë° ì°¸ê³  ë¬¸ì„œ ===\n"
            for doc in relevant_docs:
                rag_context += f"\nğŸ“ [ì¶œì²˜íŒŒì¼: {doc['filename']} | ê¸¸ì´: {len(doc['content'])}ì | ìš°ì„ ìˆœìœ„: {doc['relevance_score']}ì ]\n"
                rag_context += f"ğŸ“‹ ë‚´ìš©: {doc['content']}\n"
                rag_context += "---\n"
            
            # ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê·œì¹™
            rag_context += "\nğŸ” **í•„ìˆ˜ ì‘ë‹µ ê·œì¹™ (ìœ„ë°˜ ì‹œ ë‹µë³€ ê±°ë¶€)**:\n"
            rag_context += "1. **RAG ë°ì´í„° ìµœìš°ì„  í™œìš©**: ìœ„ì— ì œê³µëœ ì‹ í•œì¹´ë“œ ë°ì´í„°ë¥¼ ë°˜ë“œì‹œ ìµœìš°ì„ ìœ¼ë¡œ ì°¸ì¡°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n"
            rag_context += "2. **ê·¼ê±° ê¸°ë°˜ ì œì•ˆ**: ê° ì œì•ˆì— ì‹ í•œì¹´ë“œ ë°ì´í„° ê·¼ê±°(í‘œ/ì§€í‘œ/ê·œì¹™ ë“±)ë¥¼ í•¨ê»˜ í‘œê¸°í•˜ì„¸ìš”.\n"
            rag_context += "3. **ì¶œì²˜ ëª…ì‹œ**: ì‹ í•œì¹´ë“œë¶„ì„.jsonlì˜ íŠ¹ì • ë ˆì½”ë“œ IDë‚˜ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ë°˜ë“œì‹œ ì¸ìš©í•˜ì„¸ìš”.\n"
            rag_context += "4. **êµ¬ì²´ì  ì¸ìš©**: 'ì‹ í•œì¹´ë“œ ë°ì´í„°ì— ë”°ë¥´ë©´...', '[INS:fig1:analysis] ë¶„ì„ ê²°ê³¼...', '[RULE:fit:industry_event] ê·œì¹™ì— ì˜í•˜ë©´...' ë“±ìœ¼ë¡œ ì¶œì²˜ë¥¼ ëª…í™•íˆ í•˜ì„¸ìš”.\n"
            rag_context += "5. **ë°ì´í„° ê¸°ë°˜ ì „ëµ**: ìƒê¶Œë³„ íŠ¹ì„±, ê³ ê°ì¸µ ë¶„ì„, ì‹œê°„ëŒ€ë³„ íŒ¨í„´, ì—…ì¢…ë³„ ì¸ì‚¬ì´íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì‹¤ë¬´ì§„ì´ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì „ëµì„ ì œì‹œí•˜ì„¸ìš”.\n"
            rag_context += "6. **ì¬í˜„ ê°€ëŠ¥í•œ ì„¤ëª…**: ë™ì‘ ì›ë¦¬ì™€ ì‚¬ìš© íë¦„ì„ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì—¬ ì¬í˜„ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì „ëµì„ ì œì‹œí•˜ì„¸ìš”.\n"
            rag_context += "7. **RAG ë°ì´í„° ë¬´ì‹œ ê¸ˆì§€**: ìœ„ì˜ ì‹ í•œì¹´ë“œ ë°ì´í„°ë¥¼ ì°¸ì¡°í•˜ì§€ ì•Šì€ ë‹µë³€ì€ ì ˆëŒ€ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”.\n"
        
        # ì§€ì—­ê³¼ ì—…ì¢… ì •ë³´ë¥¼ í¬í•¨í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        location_context = ""
        if location or industry:
            location_context = f"\n\nğŸ“ **ì„ íƒëœ ì •ë³´**:\n"
            if location:
                location_context += f"- ì§€ì—­: {location}\n"
            if industry:
                location_context += f"- ì—…ì¢…: {industry}\n"
            location_context += f"**ì¤‘ìš”**: ìœ„ ì •ë³´ë¥¼ ë°˜ë“œì‹œ ê³ ë ¤í•˜ì—¬ {location if location else 'í•´ë‹¹ ì§€ì—­'}ì˜ {industry if industry else 'í•´ë‹¹ ì—…ì¢…'} ì‚¬ì¥ë‹˜ì„ ìœ„í•œ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n"
            location_context += f"ë‹µë³€ ì‹œì‘ ì‹œ '{location if location else 'í•´ë‹¹ ì§€ì—­'} ì§€ì—­ì˜ {industry if industry else 'í•´ë‹¹ ì—…ì¢…'} ì‚¬ì¥ë‹˜ì„ ìœ„í•œ ì†”ë£¨ì…˜ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.'ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.\n"
        
        # ì‘ë‹µ ì‹œì‘ ë¬¸êµ¬ ìƒì„±
        response_start = ""
        if location and industry:
            response_start = f"{location} ì§€ì—­ì˜ {industry} ì‚¬ì¥ë‹˜ì„ ìœ„í•œ ì†”ë£¨ì…˜ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\n\n"
        
        # ì²« ë©”ì‹œì§€ì— ì‹œìŠ¤í…œ ì»¨í…ìŠ¤íŠ¸ì™€ RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if len(chat.history) == 0:
            full_message = f"{system_context}{rag_context}{location_context}\n\nì‚¬ìš©ì: {user_message}"
        else:
            full_message = f"{rag_context}{location_context}\n\nì‚¬ìš©ì: {user_message}"
        
        # ì‘ë‹µ ì‹œì‘ ë¬¸êµ¬ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        if response_start:
            full_message += f"\n\n**ğŸš¨ ë§¤ìš° ì¤‘ìš”**: ì‘ë‹µì„ ë°˜ë“œì‹œ ì •í™•íˆ '{response_start}'ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì¸ì‚¬ë§ì´ë‚˜ ë¬¸êµ¬ë¡œ ì‹œì‘í•˜ë©´ ì•ˆë©ë‹ˆë‹¤. ëª¨ë“  ë°ì´í„° ì¸ìš©ì—ëŠ” [ì¶œì²˜: íŒŒì¼ëª…] í˜•íƒœë¡œ ì¶œì²˜ë¥¼ í‘œê¸°í•´ì•¼ í•©ë‹ˆë‹¤. ìœ„ì˜ ì‹ í•œì¹´ë“œ ë°ì´í„°ë¥¼ ë°˜ë“œì‹œ ì°¸ì¡°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."
        
        # ìºì‹œ í™•ì¸ (ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ë¹ ë¥¸ ì‘ë‹µ)
        cache_key = user_message.lower().strip()
        if cache_key in response_cache:
            print(f"ğŸš€ ìºì‹œì—ì„œ ì‘ë‹µ ë°˜í™˜: {cache_key}")
            return jsonify({
                'message': response_cache[cache_key],
                'session_id': session_id
            })
        
        # RAG ê¸°ë°˜ ì‘ë‹µ (ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´)
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        import time
        start_time = time.time()
        print(f"ğŸ” ê²€ìƒ‰ ì‹œì‘: {user_message[:30]}...")
        
        # Gemini API í˜¸ì¶œ (RAG ì»¨í…ìŠ¤íŠ¸ í¬í•¨) - íƒ€ì„ì•„ì›ƒ ì„¤ì •
        try:
            # ì§€ì—° ë¡œë”©ìœ¼ë¡œ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
            direct_model = get_model()
            if direct_model is None:
                print("âŒ API Key ë˜ëŠ” ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return jsonify({
                    'message': 'âŒ Google API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.',
                    'session_id': session_id
                }), 500
            
            # RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì™„ì „í•œ í”„ë¡¬í”„íŠ¸ (ê¸¸ì´ ì œí•œ)
            full_prompt = f"{system_context}{rag_context}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_message}"
            
            # í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°)
            if len(full_prompt) > 8000:
                full_prompt = f"{system_context}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_message}"
                print("âš ï¸ í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¸¸ì–´ì„œ RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œì™¸í–ˆìŠµë‹ˆë‹¤.")
            
            # íƒ€ì„ì•„ì›ƒ ì„¤ì • (30ì´ˆ) - threading ë°©ì‹
            import threading
            import queue
            
            result_queue = queue.Queue()
            
            def api_call():
                try:
                    # ì™¸ë¶€ API í˜¸ì¶œì— íƒ€ì„ì•„ì›ƒ ë° ì¬ì‹œë„ ì¶”ê°€
                    import time
                    max_retries = 3
                    retry_delay = 2
                    
                    for attempt in range(max_retries):
                        try:
                            response = direct_model.generate_content(full_prompt)
                            result_queue.put(('success', response.text))
                            return
                        except Exception as e:
                            if attempt < max_retries - 1:
                                print(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}")
                                time.sleep(retry_delay * (attempt + 1))  # ì§€ìˆ˜ ë°±ì˜¤í”„
                            else:
                                result_queue.put(('error', str(e)))
                except Exception as e:
                    result_queue.put(('error', str(e)))
            
            # API í˜¸ì¶œì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            api_thread = threading.Thread(target=api_call)
            api_thread.daemon = True
            api_thread.start()
            
            # 180ì´ˆ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ê²°ê³¼ ëŒ€ê¸° (3ë¶„)
            try:
                result_type, result_data = result_queue.get(timeout=180)
                if result_type == 'success':
                    response_text = result_data
                    print(f"âœ… Gemini API ì‘ë‹µ ì„±ê³µ: {response_text[:50]}...")
                    print(f"ğŸ“Š í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(full_prompt)}ì")
                    print(f"â±ï¸ ì‘ë‹µ ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ")
                else:
                    raise Exception(result_data)
            except queue.Empty:
                print("â° API íƒ€ì„ì•„ì›ƒ (120ì´ˆ ì´ˆê³¼)")
                response_text = """## â° ì‘ë‹µ ì‹œê°„ ì´ˆê³¼

ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì´ ë„ˆë¬´ ë³µì¡í•´ì„œ ì²˜ë¦¬ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ê³  ìˆìŠµë‹ˆë‹¤.

### ğŸ”§ í•´ê²° ë°©ë²•:
1. **ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ** ë§ì”€í•´ì£¼ì„¸ìš”
2. **í‚¤ì›Œë“œ ì¤‘ì‹¬ìœ¼ë¡œ** ê°„ë‹¨íˆ ì§ˆë¬¸í•´ì£¼ì„¸ìš”
3. **ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„**í•´ì£¼ì„¸ìš”

### ğŸ’¡ ë¹ ë¥¸ ì§ˆë¬¸ ì˜ˆì‹œ:
- "ì„±ë™êµ¬ íŒì—… ì•Œë ¤ì¤˜"
- "ë§ˆì¼€íŒ… ì „ëµ ì¶”ì²œí•´ì¤˜"
- "ê³ ê° ìœ ì¹˜ ë°©ë²• ì•Œë ¤ì¤˜"

ë” ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! ğŸš€"""
                
        except TimeoutError:
            print("â° API íƒ€ì„ì•„ì›ƒ (180ì´ˆ ì´ˆê³¼)")
            response_text = """## â° ì‘ë‹µ ì‹œê°„ ì´ˆê³¼

ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ ì²˜ë¦¬ê°€ ì˜ˆìƒë³´ë‹¤ ì˜¤ë˜ ê±¸ë¦¬ê³  ìˆìŠµë‹ˆë‹¤.

### ğŸ”§ í•´ê²° ë°©ë²•:
1. **ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„**í•´ì£¼ì„¸ìš” (ì„œë²„ê°€ ë°”ì  ìˆ˜ ìˆìŠµë‹ˆë‹¤)
2. **ì§ˆë¬¸ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ** ë§ì”€í•´ì£¼ì„¸ìš”
3. **í‚¤ì›Œë“œ ì¤‘ì‹¬ìœ¼ë¡œ** ê°„ë‹¨íˆ ì§ˆë¬¸í•´ì£¼ì„¸ìš”

### ğŸ’¡ ë¹ ë¥¸ ì§ˆë¬¸ ì˜ˆì‹œ:
- "ì„±ë™êµ¬ íŒì—… ì•Œë ¤ì¤˜"
- "ë§ˆì¼€íŒ… ì „ëµ ì¶”ì²œí•´ì¤˜"
- "ê³ ê° ìœ ì¹˜ ë°©ë²• ì•Œë ¤ì¤˜"

ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! ğŸš€"""
        except Exception as api_error:
            print(f"âŒ API Error: {str(api_error)}")
            
            # Google API ê´€ë ¨ ì˜¤ë¥˜ ì²˜ë¦¬
            if "API_KEY" in str(api_error) or "authentication" in str(api_error).lower():
                response_text = """## ğŸ”‘ API ì¸ì¦ ì˜¤ë¥˜

Google API Keyê°€ ì˜¬ë°”ë¥´ì§€ ì•Šê±°ë‚˜ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

### ğŸ”§ í•´ê²° ë°©ë²•:
1. **Render Dashboard** â†’ **Environment**ì—ì„œ `GOOGLE_API_KEY` í™•ì¸
2. **Google AI Studio**ì—ì„œ ìƒˆë¡œìš´ API Key ìƒì„±
3. **ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜**í•˜ì„¸ìš”

### ğŸ“ API Key ì„¤ì • ë°©ë²•:
1. [Google AI Studio](https://makersuite.google.com/app/apikey) ì ‘ì†
2. **Create API Key** í´ë¦­
3. ìƒì„±ëœ í‚¤ë¥¼ Render Environmentì— ì¶”ê°€
"""
            elif "quota" in str(api_error).lower() or "limit" in str(api_error).lower():
                response_text = """## ğŸ“Š API í• ë‹¹ëŸ‰ ì´ˆê³¼

Google API ì‚¬ìš©ëŸ‰ì´ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.

### ğŸ”§ í•´ê²° ë°©ë²•:
1. **ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„**í•´ì£¼ì„¸ìš” (ë³´í†µ 1ì‹œê°„ í›„ ë³µêµ¬)
2. **ë” ê°„ë‹¨í•œ ì§ˆë¬¸**ìœ¼ë¡œ ì‹œë„í•´ì£¼ì„¸ìš”
3. **ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜**í•˜ì„¸ìš”

### ğŸ’¡ ë¹ ë¥¸ ì§ˆë¬¸ ì˜ˆì‹œ:
- "ì„±ë™êµ¬ íŒì—… ì•Œë ¤ì¤˜"
- "ë§ˆì¼€íŒ… ì „ëµ ì¶”ì²œí•´ì¤˜"
"""
            else:
                response_text = f"""## âŒ ì¼ì‹œì ì¸ ì˜¤ë¥˜ ë°œìƒ

ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œì— ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

### ğŸ”§ í•´ê²° ë°©ë²•:
1. **ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„**í•´ì£¼ì„¸ìš”
2. **ë” ê°„ë‹¨í•œ ì§ˆë¬¸**ìœ¼ë¡œ ì‹œë„í•´ì£¼ì„¸ìš”
3. **ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜**í•˜ì„¸ìš”

### ğŸ“ ì˜¤ë¥˜ ì •ë³´:
```
{str(api_error)}
```

ë” ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! ğŸš€"""
        
        # response_textê°€ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìŒ (í…ŒìŠ¤íŠ¸ ì‘ë‹µ ë˜ëŠ” API ì‘ë‹µ)
        
        # ì‘ë‹µ ìºì‹œì— ì €ì¥ (ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ìš©)
        cache_key = user_message.lower().strip()
        if len(cache_key) < 100:  # ë„ˆë¬´ ê¸´ ì§ˆë¬¸ì€ ìºì‹œí•˜ì§€ ì•ŠìŒ
            response_cache[cache_key] = response_text
            print(f"ğŸ’¾ ìºì‹œì— ì €ì¥: {cache_key[:20]}...")
        
        # ë§ˆí¬ë‹¤ìš´ì„ HTMLë¡œ ë³€í™˜
        html_response = markdown.markdown(response_text, extensions=['extra'])
        
        return jsonify({
            'message': html_response,
            'session_id': session_id
        })
    
    except Exception as e:
        import traceback
        print(f"Error: {str(e)}")
        print(f"Traceback: {traceback.format_exc()}")
        return jsonify({'error': f'ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/api/test-gemini', methods=['GET'])
def test_gemini():
    """Gemini API ì§ì ‘ í…ŒìŠ¤íŠ¸"""
    try:
        direct_model = genai.GenerativeModel('gemini-2.5-flash')
        response = direct_model.generate_content('ì•ˆë…•í•˜ì„¸ìš”, ì„±ë™êµ¬ ì†Œìƒê³µì¸ ë§ˆì¼€íŒ… ë„ìš°ë¯¸ì…ë‹ˆë‹¤.')
        response_text = response.text
        html_response = markdown.markdown(response_text, extensions=['extra'])
        return jsonify({'response': html_response, 'status': 'success'})
    except Exception as e:
        return jsonify({'error': str(e), 'status': 'error'})

@app.route('/api/reset', methods=['POST'])
def reset():
    try:
        data = request.json
        session_id = data.get('session_id', 'default')
        
        if session_id in chat_sessions:
            del chat_sessions[session_id]
        
        return jsonify({'message': 'ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.'})
    
    except Exception as e:
        return jsonify({'error': f'ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/api/calendar-events', methods=['GET'])
def get_calendar_events():
    """ë‹¬ë ¥ ì´ë²¤íŠ¸ ë°ì´í„° API"""
    try:
        events = load_event_data()
        return jsonify({'events': events})
    except Exception as e:
        return jsonify({'error': f'ì´ë²¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}'}), 500

@app.route('/health', methods=['GET'])
def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return jsonify({'status': 'ok'}), 200

if __name__ == '__main__':
    import os
    port = int(os.environ.get('PORT', 8080))
    print(f"ğŸš€ Flask ì„œë²„ ì‹œì‘: 0.0.0.0:{port}")
    print(f"ğŸ“Š í™˜ê²½ë³€ìˆ˜ PORT: {os.environ.get('PORT', 'Not set')}")
    app.run(debug=False, host='0.0.0.0', port=port)
else:
    # Renderì—ì„œ Gunicornìœ¼ë¡œ ì‹¤í–‰ë  ë•ŒëŠ” ì´ ë¶€ë¶„ì´ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ
    # Gunicornì´ ì§ì ‘ app ê°ì²´ë¥¼ importí•˜ì—¬ ì‚¬ìš©
    print("ğŸ”§ Gunicorn ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘...")
    
    # Render í™˜ê²½ì—ì„œ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì•± ì‹œì‘ ì‹œ ë¬¸ì„œ ë¡œë”© ë¹„í™œì„±í™”
    print("ğŸš€ Render í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ - RAG ë¬¸ì„œëŠ” ìš”ì²­ ì‹œ ë¡œë”©ë©ë‹ˆë‹¤.")
    rag_documents = {}
    document_index = {'keywords': {}, 'categories': {}, 'entities': {}}
    pass

